{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "데이터 분석 활용 코드 Repository로 Kaggle과 같은 Data Competition에서 활용할 수 있는 code를 정리해놓은 곳입니다.\n",
    "\n",
    "기본적인 process를 알 수 있는 code를 시작으로 데이터 분석을 위한 모듈도 만들고 활용 code를 모을 것입니다.\n",
    "\n",
    "많은 사람들이 대회에 접해서 data 활용 스킬을 길렀으면 좋겠습니다.\n",
    "\n",
    "아직까지 ML/DL/AI 의 용어활용이 모호한 것 같습니다. \n",
    "그래서 저는 data analysis 즉, 데이터분석이 있어야 모델링하여 예측하기 때문에 데이터분석에 초점을 둘 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library Setting & Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                         # 데이터 분석 패키지\n",
    "import numpy as np                          # 계산 패키지\n",
    "\n",
    "import seaborn as sns                   # 데이터 시각화 라이브러리\n",
    "import matplotlib.pyplot as plt         # 데이터 시각화 라이브러리\n",
    "\n",
    "import sys\n",
    "import os\n",
    "print ('Python version ->', sys.version)\n",
    "print ('Numpy version ->', np.__version__)\n",
    "print ('Pandas version ->', pd.__version__)\n",
    "\n",
    "print (os.listdir('../data'))           #본인의 데이터 파일 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/' \n",
    "\n",
    "train = pd.read_csv(datapath + 'train.csv')\n",
    "test = pd.read_csv(datapath + 'test.csv')\n",
    "submission = pd.read_csv(datapath + 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train\n",
    "* 입력\n",
    "\n",
    "#### test\n",
    "* 입력\n",
    "\n",
    "#### submission\n",
    "* 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측값 및 데이터형태 확인\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.EDA & Preprocessing & Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 왜도, 첨도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column명과 dataframe을 대입하면 왜도와 첨도를 수치로 알려주고 모두 그래프로 그려줍니다.\n",
    "import math\n",
    "import seaborn as sns                   # 데이터 시각화 라이브러리\n",
    "import matplotlib.pyplot as plt         # 데이터 시각화 라이브러리\n",
    "\n",
    "def ske_kur_check(columns, df, figsize = (15,10)):\n",
    "    num = len(columns)\n",
    "\n",
    "    row_num = math.ceil(num/2)\n",
    "\n",
    "    f, ax = plt.subplots(row_num, 2, figsize = figsize)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    try:\n",
    "        for row in range(row_num):\n",
    "  \n",
    "          for col in range(2):\n",
    "            sns.distplot(df[columns[count]], ax=ax[row][col])\n",
    "            print(\"%s -> Skewness: %f, Kurtosis: %f\" %  (columns[count],df[columns[count]].skew(),\n",
    "                                                 df[columns[count]].kurt()))\n",
    "            count += 1\n",
    "\n",
    "    except IndexError:\n",
    "        print('columns count is odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_columns = train.columns[:-1]\n",
    "indep_column = train.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[dep_columns]\n",
    "y_train = train[indep_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관관계 확인 (Correlation Check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Model Traing & Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 제 기준에서 경험적으로 봤을 때, XGBoost와 LightGBM이 제일 강력한 모델인 것 같습니다.\n",
    "\n",
    "추가적으로 sklearn에 RandomForest도 활용할 수 있다고 생각합니다. (sklearn.ensemble.randomforest~)\n",
    "\n",
    "신경망모델을 사용하지 않으면, 위 두가지 모델이 제일 강력하여 기본적으로 사용하는 코드를 작성했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb                       # XGBoost 패키지\n",
    "import lightgbm as lgb                      # LightGBM - 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_train(X_train, y_train, params):\n",
    "    \n",
    "    train = xgb.DMatrix(data = X_train, label = y_train)\n",
    "    \n",
    "    print(\"cv start\")\n",
    "    cv_result = xgb.cv(\n",
    "        params,\n",
    "        train,\n",
    "        num_boost_round=99999,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=100,\n",
    "        stratified=False,\n",
    "        verbose_eval=10)\n",
    "\n",
    "    print(\"train start\")\n",
    "    xgb_model = xgb.train(\n",
    "        params,\n",
    "        train,\n",
    "        num_boost_round=cv_result.shape[0])\n",
    "    \n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y가 한개인 경우\n",
    "\n",
    "xgb_params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'mae',\n",
    "            'seed':2020\n",
    "            }\n",
    "\n",
    "xgb_models = xgb_train(X_train, y_train, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y가 여러개 인경우\n",
    "\n",
    "xgb_params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'seed':2020\n",
    "            }\n",
    "\n",
    "xgb_models = {}\n",
    "for label in y_train.columns:\n",
    "    print('train column : ', label)\n",
    "    xgb_models[label] = xgb_train(train_df, y_train[label], xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_train(X_train, y_train, params):\n",
    "    features = list(X_train.columns)\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    \n",
    "    train = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    print(\"cv start\")\n",
    "    cv_result = lgb.cv(\n",
    "        params,\n",
    "        train,\n",
    "        num_boost_round=99999,\n",
    "        nfold=5,\n",
    "        early_stopping_rounds=10,\n",
    "        stratified=False,\n",
    "        verbose_eval=500\n",
    "    )\n",
    "\n",
    "    print(\"train start\")\n",
    "    lgb_model = lgb.train(\n",
    "        params,\n",
    "        train,\n",
    "        num_boost_round=len(cv_result[\"l1-mean\"])\n",
    "    )\n",
    "    \n",
    "    print(\"importance feature\")\n",
    "    \n",
    "    feature_importance_df['feature'] = features\n",
    "    feature_importance_df['importance'] = lgb_model.feature_importance()\n",
    "    \n",
    "    return lgb_model, feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y가 한개인경우\n",
    "\n",
    "lgb_params = {\n",
    "        \"objective\":\"regression\",\n",
    "        \"metrics\":\"mae\",\n",
    "        \"learning_rate\":0.01,\n",
    "        'seed':2020\n",
    "}\n",
    "\n",
    "lgb_models, lgb_features = lgb_train(X_train, y_train, lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y가 여러개인경우\n",
    "\n",
    "lgb_params = {\n",
    "        \"objective\":\"regression\",\n",
    "        \"metrics\":\"mae\",\n",
    "        \"learning_rate\":0.01,\n",
    "        'seed':2020\n",
    "}\n",
    "\n",
    "lgb_models = {}\n",
    "lgb_features = {}\n",
    "for label in y_train.columns:\n",
    "    print('train column : ', label)\n",
    "    lgb_models[label], lgb_features[label] = lgb_train(train_df, y_train[label], lgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 2가지 모델을 합치는 경우에선 항상 좋은 결과를 이뤄냈기에 ensemble 기법중 가장 간단한 평균법을 사용하여 최종 결과물을 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pred = xgb_model.predict(xgb.DMatrix(test.loc[:, dep_columns]))\n",
    "lgb_pred = lgb_model.predict(test.loc[:, dep_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[:, 1] = (xgb_pred+lgb_pred)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save submission file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission file 관리를 위해 파일 저장시 현재시간을 파일이름으로 저장\n",
    "#신경망 모델 활용 시 weights 저장 파일이름에서도 활용 가능\n",
    "\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "date_today = datetime.now(timezone('Asia/Seoul')).strftime(\"%Y%m%dT%H%M\")\n",
    "print('today time : ' + date_today)\n",
    "\n",
    "submission.to_csv(datapath + '{}.csv'.format(date_today), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
